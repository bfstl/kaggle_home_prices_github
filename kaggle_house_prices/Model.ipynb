{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Modeling Tools\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import (ExtraTreesRegressor, RandomForestRegressor, \n",
    "                              AdaBoostRegressor, GradientBoostingRegressor)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import (KNeighborsRegressor, RadiusNeighborsRegressor)\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Grid Search Tool\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters) \n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_model.csv\", index_col=0)\n",
    "validation = pd.read_csv(\"test_model.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-set qualifiers for the grid search\n",
    "models = {\n",
    "     #'RandomForestRegressor': RandomForestRegressor(),\n",
    "      'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "     #'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "     #'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "     'XGBRegressor' : XGBRegressor()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    #'RandomForestRegressor': {'n_estimators': [10, 20, 40, 60, 75, 100]},\n",
    "     'GradientBoostingRegressor': {'n_estimators': [10, 20, 40, 60, 75, 100],\n",
    "                                   'learning_rate': [.1, .25, .5, .75, .9],\n",
    "                                   'loss' : ['ls', 'lad', 'huber', 'quantile'], \n",
    "                                   'max_depth' : [1, 3, 5, 7, 10],\n",
    "                                   'subsample': [.5, .75, 1]},\n",
    "    #'ExtraTreesRegressor': {'n_estimators': [10, 20, 40, 60, 75, 100] },    \n",
    "    #'AdaBoostRegressor': {'n_estimators': [10, 20, 40, 60, 75, 100],\n",
    "    #                       'learning_rate': [.1, .25, .5, .75, .9]},\n",
    "    'XGBRegressor': {'max_depth':[4 ,5, 6],\n",
    "                     #'gamma':[1, 2, 3, 5, 10],\n",
    "                     'min_child_weight':[.5, .75],\n",
    "                     'subsample': [.5],\n",
    "                     'learning_rate': [.06, .05, .04]},\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split training and test into dependent (y), vs independent (x) variables\n",
    "train_y=train['SalePrice']\n",
    "train_x=train.drop(['SalePrice', \"Id\"], axis = 1)\n",
    "\n",
    "test_y=test['SalePrice']\n",
    "test_x=test.drop(['SalePrice', \"Id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingRegressor.\n",
      "Fitting 3 folds for each of 1800 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 439 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 689 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1039 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1489 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2039 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2824 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3650 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4500 tasks      | elapsed:  4.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for XGBRegressor.\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5400 out of 5400 | elapsed:  5.9min finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "#Feed each product set a bunch of models and run the grid search\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "helper.fit(train_x, train_y, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "scores = helper.score_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20523.7</td>\n",
       "      <td>-18405.8</td>\n",
       "      <td>-14922.2</td>\n",
       "      <td>2482.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-19987.3</td>\n",
       "      <td>-18423.6</td>\n",
       "      <td>-15430.8</td>\n",
       "      <td>2116.93</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20177.5</td>\n",
       "      <td>-18477.3</td>\n",
       "      <td>-15675.7</td>\n",
       "      <td>1996.09</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20104.7</td>\n",
       "      <td>-18569</td>\n",
       "      <td>-16082.8</td>\n",
       "      <td>1774.16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>huber</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-19542.6</td>\n",
       "      <td>-18576.5</td>\n",
       "      <td>-17305.2</td>\n",
       "      <td>938.597</td>\n",
       "      <td>0.1</td>\n",
       "      <td>huber</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20493.9</td>\n",
       "      <td>-18589.9</td>\n",
       "      <td>-17142</td>\n",
       "      <td>1405.87</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ls</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20272.2</td>\n",
       "      <td>-18606</td>\n",
       "      <td>-16258.1</td>\n",
       "      <td>1708.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20276.4</td>\n",
       "      <td>-18615.5</td>\n",
       "      <td>-15794.4</td>\n",
       "      <td>2005.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-19823.4</td>\n",
       "      <td>-18619.7</td>\n",
       "      <td>-16583.6</td>\n",
       "      <td>1447.73</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-20660</td>\n",
       "      <td>-18628.6</td>\n",
       "      <td>-16471.5</td>\n",
       "      <td>1712.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-20660</td>\n",
       "      <td>-18628.6</td>\n",
       "      <td>-16471.5</td>\n",
       "      <td>1712.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20339.2</td>\n",
       "      <td>-18631.4</td>\n",
       "      <td>-16041.2</td>\n",
       "      <td>1862.31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-19307.2</td>\n",
       "      <td>-18656.8</td>\n",
       "      <td>-17730.3</td>\n",
       "      <td>672.695</td>\n",
       "      <td>0.1</td>\n",
       "      <td>huber</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-20487.8</td>\n",
       "      <td>-18661.2</td>\n",
       "      <td>-16795.8</td>\n",
       "      <td>1507.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-20487.8</td>\n",
       "      <td>-18661.2</td>\n",
       "      <td>-16795.8</td>\n",
       "      <td>1507.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20363.7</td>\n",
       "      <td>-18737.4</td>\n",
       "      <td>-16009.4</td>\n",
       "      <td>1940.84</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-19692.8</td>\n",
       "      <td>-18748.8</td>\n",
       "      <td>-17020.5</td>\n",
       "      <td>1223.79</td>\n",
       "      <td>0.1</td>\n",
       "      <td>huber</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-19874.5</td>\n",
       "      <td>-18751.1</td>\n",
       "      <td>-16831.6</td>\n",
       "      <td>1363.81</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lad</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-21242.5</td>\n",
       "      <td>-18764.6</td>\n",
       "      <td>-16403.6</td>\n",
       "      <td>1977.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ls</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-21027.7</td>\n",
       "      <td>-18783.9</td>\n",
       "      <td>-16583.6</td>\n",
       "      <td>1814.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      estimator min_score mean_score max_score std_score  \\\n",
       "124   GradientBoostingRegressor  -20523.7   -18405.8  -14922.2   2482.33   \n",
       "155   GradientBoostingRegressor  -19987.3   -18423.6  -15430.8   2116.93   \n",
       "160   GradientBoostingRegressor  -20177.5   -18477.3  -15675.7   1996.09   \n",
       "231   GradientBoostingRegressor  -20104.7     -18569  -16082.8   1774.16   \n",
       "249   GradientBoostingRegressor  -19542.6   -18576.5  -17305.2   938.597   \n",
       "48    GradientBoostingRegressor  -20493.9   -18589.9    -17142   1405.87   \n",
       "138   GradientBoostingRegressor  -20272.2     -18606  -16258.1    1708.2   \n",
       "142   GradientBoostingRegressor  -20276.4   -18615.5  -15794.4   2005.25   \n",
       "123   GradientBoostingRegressor  -19823.4   -18619.7  -16583.6   1447.73   \n",
       "1811               XGBRegressor    -20660   -18628.6  -16471.5   1712.28   \n",
       "1810               XGBRegressor    -20660   -18628.6  -16471.5   1712.28   \n",
       "179   GradientBoostingRegressor  -20339.2   -18631.4  -16041.2   1862.31   \n",
       "213   GradientBoostingRegressor  -19307.2   -18656.8  -17730.3   672.695   \n",
       "1805               XGBRegressor  -20487.8   -18661.2  -16795.8   1507.51   \n",
       "1804               XGBRegressor  -20487.8   -18661.2  -16795.8   1507.51   \n",
       "153   GradientBoostingRegressor  -20363.7   -18737.4  -16009.4   1940.84   \n",
       "208   GradientBoostingRegressor  -19692.8   -18748.8  -17020.5   1223.79   \n",
       "159   GradientBoostingRegressor  -19874.5   -18751.1  -16831.6   1363.81   \n",
       "389   GradientBoostingRegressor  -21242.5   -18764.6  -16403.6   1977.18   \n",
       "1808               XGBRegressor  -21027.7   -18783.9  -16583.6   1814.55   \n",
       "\n",
       "     learning_rate   loss max_depth min_child_weight n_estimators subsample  \n",
       "124            0.1    lad         3              NaN          100      0.75  \n",
       "155            0.1    lad         7              NaN           60         1  \n",
       "160            0.1    lad         7              NaN          100      0.75  \n",
       "231            0.1  huber         5              NaN          100       0.5  \n",
       "249            0.1  huber         7              NaN          100       0.5  \n",
       "48             0.1     ls         5              NaN           75       0.5  \n",
       "138            0.1    lad         5              NaN           75       0.5  \n",
       "142            0.1    lad         5              NaN          100      0.75  \n",
       "123            0.1    lad         3              NaN          100       0.5  \n",
       "1811          0.05    NaN         6             0.75          NaN       0.5  \n",
       "1810          0.05    NaN         6              0.5          NaN       0.5  \n",
       "179            0.1    lad        10              NaN          100         1  \n",
       "213            0.1  huber         3              NaN          100       0.5  \n",
       "1805          0.06    NaN         6             0.75          NaN       0.5  \n",
       "1804          0.06    NaN         6              0.5          NaN       0.5  \n",
       "153            0.1    lad         7              NaN           60       0.5  \n",
       "208            0.1  huber         3              NaN           60      0.75  \n",
       "159            0.1    lad         7              NaN          100       0.5  \n",
       "389           0.25     ls         3              NaN           60         1  \n",
       "1808          0.05    NaN         5              0.5          NaN       0.5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "#clf = XGBRegressor(gamma = 5,  max_depth = 3, min_child_weight = .5) #best model so far\n",
    "#clf = XGBRegressor(gamma = 1,  learning_rate = .06, max_depth = 5, min_child_weight = .5, subsample = .5)\n",
    "clf = GradientBoostingRegressor(learning_rate = .1, loss = 'lad', max_depth = 3, n_estimators = 100,\n",
    "                                subsample = 1)\n",
    "model=clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring\n",
    "submission = pd.DataFrame(validation[\"Id\"])\n",
    "submission[\"SalePrice\"] = clf.predict(validation.fillna(0).drop(\"Id\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_03042018_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
